# ğŸ§  Mamba-ViT Hybrid Image Dehazing

## ğŸŒ« Overview

This repository implements a **hybrid deep learning model** for **image dehazing** that integrates a **Vision Transformer (ViT)** encoder and a **Mamba recurrent refinement module**.

The model enhances feature understanding and spatial consistency by combining:

- ğŸ§© **Local texture extraction** â€” CNN Encoder  
- ğŸŒ **Global context modeling** â€” Vision Transformer  
- ğŸ” **Sequential feature refinement** â€” Mamba GRU  
- ğŸ¨ **Image reconstruction** â€” CNN Decoder  

It is trained and evaluated on the **SOTS (RESIDE)** dataset and outputs clean, dehazed images with **high PSNR and SSIM**.

---

## ğŸš€ Features

âœ… DEM-Free, purely image-based model  
âœ… End-to-end training with PyTorch  
âœ… Supports PSNR & SSIM metric evaluation  
âœ… Visual comparison (Hazy â†’ Dehazed â†’ Ground Truth)  
âœ… Modular architecture (ViT + Mamba + CNN fusion)  
âœ… Lightweight â€” runs smoothly on mid-range GPUs  



## ğŸ§  Model Components

| Component | Description |
|------------|-------------|
| **Encoder** | Two-layer CNN for local feature extraction |
| **SimpleViT** | Lightweight Vision Transformer for global context summarization |
| **SimpleMamba** | GRU-based sequential block to refine ViT embeddings |
| **Decoder** | CNN block for reconstructing the clean image |
| **Fusion** | Adds refined global features back to encoder outputs |

---

## ğŸ“‚ Dataset

**Dataset Used:** [RESIDE SOTS Outdoor](https://sites.google.com/view/reside-dehaze-datasets)

### Folder Structure
â”œâ”€â”€ hazy_processed/ # input hazy images
â”œâ”€â”€ GT/ # corresponding clear ground truth images



---

## âš™ï¸ Installation

```bash
git clone https://github.com/<your-username>/Mamba-ViT-Dehazing.git
cd Mamba-ViT-Dehazing
pip install torch torchvision scikit-learn matplotlib Pillow
ğŸ§ª Training
bash

python train_dehazing.py
Automatically splits data into 80% Train / 20% Test

Trains for 70 epochs

Saves model as:

bash
Copy code
mamba_vit_100dddehazing.pth
ğŸ“ˆ Evaluation Metrics
Metric	Description
PSNR	Peak Signal-to-Noise Ratio â€“ measures reconstruction fidelity
SSIM	Structural Similarity Index â€“ evaluates perceptual similarity

Both metrics are computed per image and averaged across the dataset.

ğŸ–¼ Results Visualization
During testing, side-by-side comparisons are displayed as:

Hazy Input â†’ Predicted Output â†’ Ground Truth

Example Output:

yaml
Copy code
Epoch 70, Loss: 0.0084, PSNR: 34.82, SSIM: 0.9231
Test Set â€” Avg PSNR: 35.42, Avg SSIM: 0.9287
ğŸ“Š Example Visualization (Optional)
You can visualize the model flow using Matplotlib:

python

import matplotlib.pyplot as plt

stages = [
    "Input (Hazy Image)",
    "CNN Encoder",
    "Vision Transformer (ViT)",
    "Mamba (GRU Refinement)",
    "Feature Fusion",
    "CNN Decoder",
    "Output (Dehazed Image)"
]

plt.figure(figsize=(12, 2))
for i, stage in enumerate(stages):
    plt.text(i * 1.5, 0, stage, fontsize=11,
             bbox=dict(facecolor='skyblue', edgecolor='black', boxstyle='round,pad=0.3'))
    if i < len(stages) - 1:
        plt.arrow(i * 1.5 + 0.9, 0, 0.5, 0,
                  head_width=0.05, head_length=0.1, fc='k', ec='k')

plt.axis('off')
plt.title("Mamba-ViT Hybrid Dehazing Pipeline", fontsize=13, pad=10)
plt.show()
ğŸ’¾ Model Saving
After training, the model weights are saved as:

python

torch.save(model.state_dict(), "mamba_vit_100dddehazing.pth")
ğŸ§â€â™‚ï¸ Author
Pranjal Pandey
B.Tech â€” Mechatronics and Automation
Indian Institute of Information Technology, Bhagalpur
ğŸ“§ pranjal.230103027@iiitbh.ac.in

ğŸ§¾ Citation
If you use this repository or build upon it, please cite:

bibtex

@software{pranjal2025mambavitdehazing,
  title  = {Mamba-ViT Hybrid Image Dehazing},
  author = {Pandey, Pranjal},
  year   = {2025},
  url    = {https://github.com/<your-username>/Mamba-ViT-Dehazing}
}
