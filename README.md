ğŸ§  README: Mamba-ViT Hybrid Image Dehazing
ğŸŒ« Overview

This repository implements a hybrid deep learning model for image dehazing that integrates a Vision Transformer (ViT) encoder and a Mamba recurrent refinement module.
The model enhances feature understanding and spatial consistency by combining:

Local texture extraction (CNN Encoder)

Global context modeling (ViT)

Sequential feature refinement (Mamba GRU)

Image reconstruction (CNN Decoder)

It is trained and evaluated on the SOTS (RESIDE) dataset and outputs clean, dehazed images with high PSNR and SSIM.

ğŸš€ Features

âœ… DEM-Free, purely image-based model
âœ… End-to-end training with PyTorch
âœ… Supports PSNR & SSIM metric evaluation
âœ… Visual comparison (Hazy â†’ Dehazed â†’ Ground Truth)
âœ… Modular architecture (ViT + Mamba + CNN fusion)
âœ… Lightweight, easy to train on mid-range GPUs

ğŸ§© Architecture Diagram
Line Diagram (Model Flow)
Input (Hazy Image)
        â”‚
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  CNN Encoder (3â†’128)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Vision Transformer â”‚
 â”‚ (Global Context)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Mamba (GRU Block)  â”‚
 â”‚ (Sequential Refinement) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Projection + Fusionâ”‚
 â”‚ (Add to Encoder)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  CNN Decoder (128â†’3)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
Output (Dehazed Image)

ğŸ§  Model Components
Component	Description
Encoder	Two-layer CNN for local feature extraction
SimpleViT	Lightweight Vision Transformer-like feature summarizer
SimpleMamba	GRU-based sequential block to refine ViT embeddings
Decoder	CNN block to reconstruct the clean image
Fusion	Adds back the refined global context to spatial encoder features
ğŸ“‚ Dataset

Dataset Used: RESIDE SOTS Outdoor

Folder Structure:

â”œâ”€â”€ hazy_processed/   # input hazy images
â”œâ”€â”€ GT/               # corresponding clear ground truth images

âš™ï¸ Installation
git clone https://github.com/<your-username>/Mamba-ViT-Dehazing.git
cd Mamba-ViT-Dehazing
pip install torch torchvision scikit-learn matplotlib Pillow

ğŸ§ª Training
python train_dehazing.py


The model automatically splits data into 80% train / 20% test

Trains for 70 epochs

Saves model weights as mamba_vit_100dddehazing.pth

ğŸ“ˆ Evaluation Metrics
Metric	Description
PSNR	Peak Signal-to-Noise Ratio for reconstruction quality
SSIM	Structural Similarity Index for perceptual similarity

Both metrics are computed per image and averaged across the dataset.

ğŸ–¼ Results Visualization

During testing, the script displays side-by-side comparisons:

Hazy Input | Predicted Output | Ground Truth


Example Output:

Epoch 70, Loss: 0.0084, PSNR: 34.82, SSIM: 0.9231

Test Set - Average PSNR: 35.42, Average SSIM: 0.9287

ğŸ“Š Example Visualization (Python)

You can generate a diagram showing the model flow using Matplotlib:

import matplotlib.pyplot as plt

stages = [
    "Input (Hazy Image)",
    "CNN Encoder",
    "Vision Transformer (ViT)",
    "Mamba (GRU Refinement)",
    "Feature Fusion",
    "CNN Decoder",
    "Output (Dehazed Image)"
]

plt.figure(figsize=(12, 2))
for i, stage in enumerate(stages):
    plt.text(i * 1.5, 0, stage, fontsize=11, bbox=dict(facecolor='skyblue', edgecolor='black', boxstyle='round,pad=0.3'))
    if i < len(stages) - 1:
        plt.arrow(i * 1.5 + 0.9, 0, 0.5, 0, head_width=0.05, head_length=0.1, fc='k', ec='k')

plt.axis('off')
plt.title("Mamba-ViT Hybrid Dehazing Pipeline", fontsize=13, pad=10)
plt.show()

ğŸ’¾ Model Saving

After training:

torch.save(model.state_dict(), "mamba_vit_100dddehazing.pth")

ğŸ§â€â™‚ï¸ Author

Pranjal Pandey
B.Tech, Mechatronics and Automation
Indian Institute of Information Technology, Bhagalpur
ğŸ“§ pranjal.230103027@iiitbh.ac.in

ğŸ§¾ Citation

If you use this work or build upon it, please cite:

@software{pranjal2025mambavitdehazing,
  title={Mamba-ViT Hybrid Image Dehazing},
  author={Pandey, Pranjal},
  year={2025},
  url={https://github.com/<your-username>/Mamba-ViT-Dehazing}
}
